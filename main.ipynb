{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e73174be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Directories of interest\n",
    "# include folders that you might want the llm to have access to\n",
    "DIRECTORIES = [r\"C:\\\\Users\\\\Jamin Carter\\\\Downloads\\\\web_archive\", r\"D:\\Project\\Web-scraping\\TestFolder\"]\n",
    "    \n",
    "    \n",
    "files_to_vectorize=[]\n",
    "for dir in DIRECTORIES:\n",
    "    files = Path(dir).glob(\"*\")\n",
    "    for file_path in files:\n",
    "        if file_path.is_file():\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                files_to_vectorize.append(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca78a334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files to vectorize: 72\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total files to vectorize: {len(files_to_vectorize)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593e0466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_game8_co_'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_vectorize[7][55:65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6934749",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: './db/sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m     os.makedirs(\u001b[33m\"\u001b[39m\u001b[33m./db/sqlite\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(\u001b[33m\"\u001b[39m\u001b[33m./db/chroma\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./db/sqlite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:228\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mFileExistsError\u001b[39m: [WinError 183] Cannot create a file when that file already exists: './db/sqlite'"
     ]
    }
   ],
   "source": [
    "# DIRECTORY SETUP\n",
    "import os\n",
    "if not os.path.exists(\"./db/sqlite\"):\n",
    "    os.makedirs(\"./db/sqlite\")\n",
    "    \n",
    "\n",
    "if not os.path.exists(\"./db/chroma\"):\n",
    "    os.makedirs(\"./db/chroma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ec1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "import sqlite3\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "# --- SQLite ---\n",
    "conn = sqlite3.connect(\"./db/sqlite/isVectorized.db\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA journal_mode=WAL;\")\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS vectorized_files (\n",
    "    file_id TEXT PRIMARY KEY,\n",
    "    hash TEXT\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "def is_vectorized(file_id, file_hash) -> bool:\n",
    "    cur.execute(\n",
    "        \"SELECT 1 FROM vectorized_files WHERE file_id=? AND hash=?\",\n",
    "        (file_id, file_hash)\n",
    "    )\n",
    "    return cur.fetchone() is not None\n",
    "\n",
    "\n",
    "# --- Chroma ---\n",
    "client = chromadb.PersistentClient(path=\"./db/chroma/\")\n",
    "collection = client.get_or_create_collection(\"ALL_TEXT_FILES\")\n",
    "\n",
    "\n",
    "def clean_content(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "\n",
    "    lines = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            lines.append(line)\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def chunking(text: str, chunk_size: int, overlap: int) -> list[str]:\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    text_length = len(text)\n",
    "\n",
    "    while start < text_length:\n",
    "        end = min(start + chunk_size, text_length)\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "        if end == text_length:\n",
    "            break\n",
    "\n",
    "        start += chunk_size - overlap\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def add_to_chroma(file_path: str):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = f.read()\n",
    "\n",
    "    content = clean_content(raw)\n",
    "    file_hash = hashlib.md5(content.encode(\"utf-8\")).hexdigest()\n",
    "\n",
    "    if is_vectorized(file_path, file_hash):\n",
    "        #tqdm.write(f\"[DEV] Skipping AV:{file_path[50:70]}\")\n",
    "        return\n",
    "\n",
    "    #tqdm.write(f\"[DEV] Attempting AV:{file_path[50:70]}\")\n",
    "\n",
    "    chunks = chunking(content, 1000, 200)\n",
    "\n",
    "    # 1️⃣ Add to Chroma FIRST\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        collection.add(\n",
    "            documents=[chunk],\n",
    "            metadatas=[{\"file_id\": file_path}],\n",
    "            ids=[f\"{file_path}::chunk_{i}\"]\n",
    "        )\n",
    "\n",
    "    # 2️⃣ Mark vectorized AFTER success\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO vectorized_files (file_id, hash)\n",
    "        VALUES (?, ?)\n",
    "        ON CONFLICT(file_id) DO UPDATE SET\n",
    "            hash = excluded.hash\n",
    "        \"\"\",\n",
    "        (file_path, file_hash)\n",
    "    )\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c31752f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_to_chroma(files_to_vectorize[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b85f1bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ids': ['C:\\\\Users\\\\Jamin Carter\\\\Downloads\\\\web_archive\\\\2025-12-18__github_com_open_webui_open_webui.txt::chunk_0'], 'embeddings': None, 'documents': [\"Skip to content\\nYou signed in with another tab or window. Reload to refresh your session.\\nYou signed out in another tab or window. Reload to refresh your session.\\nYou switched accounts on another tab or window. Reload to refresh your session.\\nDismiss alert\\nopen-webui\\nPublic\\nSponsor\\nWatch\\nCouldn't load subscription status.\\nRetry\\nUh oh!\\nThere was an error while loading. Please reload this page.\\nFork\\n16.6k\\nFork your own copy of open-webui/open-webui\\nForks could not be loaded\\nLoading\\nUh oh!\\nThere was an error while loading. Please reload this page.\\nStarred\\n118k\\nLoading\\nUh oh!\\nThere was an error while loading. Please reload this page.\\nStar\\n118k\\nLoading\\nUh oh!\\nThere was an error while loading. Please reload this page.\\nWatch536\\nSponsor open-webui/open-webui\\nSponsor open-webui/open-webui\\nGitHub Sponsors\\nLearn more about Sponsors\\ntjbck\\ntjbck\\nSponsor\\nLearn more about funding links in repositories.\\nReport abuse\\nFork your own copy of open-webui/open-webui\\nUnstar this repository\\nLoading\\nUh oh!\\nTher\"], 'uris': None, 'included': ['documents', 'metadatas'], 'data': None, 'metadatas': [{'file_id': 'C:\\\\Users\\\\Jamin Carter\\\\Downloads\\\\web_archive\\\\2025-12-18__github_com_open_webui_open_webui.txt'}]}\n"
     ]
    }
   ],
   "source": [
    "result = collection.get(\n",
    "    limit=1,\n",
    "    include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4565be1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing files: 100%|██████████| 72/72 [03:49<00:00,  3.19s/it, file=]                                                                                    \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pbar = tqdm(files_to_vectorize, desc=\"Vectorizing files\")\n",
    "\n",
    "for file_path in pbar:\n",
    "    pbar.set_postfix(file=file_path[56:])  # show last part only\n",
    "    add_to_chroma(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ede7069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58796841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
